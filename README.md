# ğŸš€ Pipeline ETL - GeraÃ§Ã£o e IngestÃ£o de Dados de Compras ğŸ›ï¸

[![Imagem](pipeline.png)]

Este projeto implementa um **Pipeline ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga)** que simula a ingestÃ£o contÃ­nua de grandes volumes de dados de compras gerados por uma API Mock em um banco de dados **PostgreSQL**.

Ele serve como um excelente *playground* para demonstrar proficiÃªncia em:

1.  Desenvolvimento de **APIs** com **FastAPI** para simulaÃ§Ã£o de dados.
2.  OrquestraÃ§Ã£o de um processo de **ETL** em Python.
3.  ValidaÃ§Ã£o de dados utilizando **Pydantic**.
4.  Uso do **SQLAlchemy** (ORM/Core).
5.  Uso de **Docker** e **Docker Compose** para isolamento e orquestraÃ§Ã£o de microsserviÃ§os.

---

## ğŸ¯ Objetivo

O principal objetivo Ã© criar um fluxo de dados confiÃ¡vel e escalÃ¡vel, simulando a chegada de informaÃ§Ãµes transacionais (**compras**) que podem ser usadas posteriormente para anÃ¡lises e relatÃ³rios.

## ğŸ’¡ Arquitetura do Projeto

O pipeline segue um fluxo linear, encapsulado em contÃªineres Docker para facilitar a execuÃ§Ã£o e garantir um ambiente consistente.

| Etapa | Componente Principal | Tecnologia | FunÃ§Ã£o |
| :---: | :---: | :---: | :---: |
| **GeraÃ§Ã£o** | `fastapi.py`, `fake_generate.py` | **FastAPI**, **Faker**, Uvicorn | ExpÃµe um endpoint que gera **dados de compras *mock*** em tempo real. |
| **OrquestraÃ§Ã£o/ExtraÃ§Ã£o** | `main.py`, `APIOrchestrator.py` | Python, `requests` | Orquestra o *polling*, extrai (`GET`) os dados da API em lotes. |
| **ValidaÃ§Ã£o/TransformaÃ§Ã£o** | `APIOrchestrator.py` | **Pydantic** | Valida a estrutura e tipos de dados extraÃ­dos contra o `CompraSchema`. |
| **Carga** | `APIOrchestrator.py` | **SQLAlchemy**, `psycopg2` | Conecta ao **PostgreSQL** e insere os dados validados na tabela. |
| **ContÃªineres** | `Dockerfile`, `docker-compose.yml` | **Docker**, **Docker Compose** | Empacota e orquestra o banco de dados, a API e os *workers* ETL. |

---

## ğŸ› ï¸ Tecnologias Utilizadas

| Categoria | Tecnologia | Uso no Projeto |
| :---: | :---: | :---: |
| **Linguagem** | Python 3.13 | Linguagem principal para ETL e API. |
| **API** | **FastAPI**, **Uvicorn** | CriaÃ§Ã£o da API de GeraÃ§Ã£o de Dados. |
| **Modelagem/ValidaÃ§Ã£o** | **Pydantic** | DefiniÃ§Ã£o do *Schema* (`CompraSchema`) e validaÃ§Ã£o rigorosa dos dados. |
| **Database** | **PostgreSQL** | Banco de dados relacional para persistÃªncia de dados. |
| **ORM/ConexÃ£o** | **SQLAlchemy** (Core) | CriaÃ§Ã£o da tabela e inserÃ§Ã£o eficiente dos registros. |
| **Infraestrutura** | **Docker**, **Docker Compose** | Empacotamento e orquestraÃ§Ã£o dos serviÃ§os (DB, API, ETL Worker). |
| **GeraÃ§Ã£o de Dados** | **Faker** (pt\_BR) | CriaÃ§Ã£o de dados de compras realistas em portuguÃªs. |

---

## âš™ï¸ Como Executar o Projeto (Localmente com Docker)

### PrÃ©-requisitos

Certifique-se de ter o **Docker** instalado em sua mÃ¡quina.

### 1. Clonar o RepositÃ³rio

```bash
git clone git@github.com:EriickHenriique/etl_fake_database.git
cd etl_fake_database
```

### 2. Subir os ServiÃ§os

O arquivo `docker-compose.yml` define e configura quatro serviÃ§os: **postgres**, **pgadmin**, **fastapi** e **etl_worker**.

Execute o comando abaixo na raiz do projeto:

```bash
docker compose up --build
```

#### O que acontece apÃ³s o comando?

- Os serviÃ§os **postgres (DB)** e **fastapi (API Mock)** sÃ£o iniciados.  
- O serviÃ§o **etl_worker** aguarda a inicializaÃ§Ã£o completa do PostgreSQL.  
- O **etl_worker** inicia o script `main.py`, que comeÃ§a o ciclo de ExtraÃ§Ã£o/ValidaÃ§Ã£o/Carga:
  - Faz o request para a API do fastapi.
  - Valida os dados com Pydantic.
  - Insere **10.000 linhas** no PostgreSQL por execuÃ§Ã£o.
  - Repete este processo **50 vezes** com um delay de 5 segundos.

Os logs do processo ETL serÃ£o exibidos no seu terminal.

---

### 3. Acompanhamento (Opcional)

VocÃª pode inspecionar o banco de dados via **pgAdmin**:

- **URL:** http://localhost:5050  
- **Email:** fake123@gmail.com  
- **Senha:** postgres123  

**ConexÃ£o com DB (postgres):**

| ParÃ¢metro | Valor |
|------------|--------|
| Host | postgres |
| Port | 5432 |
| Database | etl_fakedata |
| User | postgres |
| Password | postgres |

A tabela criada serÃ¡ `tabela_compras` dentro do banco `etl_fakedata`.

### 4. Parar e Limpar os ServiÃ§os

Para parar e remover os contÃªineres, redes e volumes:

```bash
docker compose down
```

Para remover **TUDO**, incluindo o volume de dados do banco:

```bash
docker compose down -v
```

---

## ğŸ“‚ Estrutura de CÃ³digo

```
etl_fake_database/
â”‚
â”œâ”€â”€ main.py                        # Ponto de entrada do Worker ETL
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ APIOrchestrator.py         # Classe central do ETL (ExtraÃ§Ã£o, ValidaÃ§Ã£o e Carga)
â”‚   â”œâ”€â”€ contracts/
â”‚   â”‚   â””â”€â”€ contracts.py           # Define o CompraSchema (Pydantic)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ fake_generate.py       # LÃ³gica de mock de dados (Faker)
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ fastapi.py             # Endpoint /gerar_compra/{param}
â”œâ”€â”€ docker-compose.yml             # Orquestra os serviÃ§os (DB, API, ETL Worker)
â””â”€â”€ Dockerfile                     # Define o ambiente Python do projeto
```

ğŸ“˜ **Autor:** Erick Henrique  


